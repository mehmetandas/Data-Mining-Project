{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehmetandas/Data-Mining-Project/blob/master/Target_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UedSDsKfvhNk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d313ee2-0a39-47a9-9aab-07126e64fa06",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Veri işleme\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import ast\n",
        "import json\n",
        "from collections import defaultdict\n",
        "from itertools import combinations\n",
        "\n",
        "# Görselleştirme\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Sklearn - Ön işleme\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder, StandardScaler\n",
        "\n",
        "# Sklearn - Modelleme\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
        "\n",
        "# XGBoost\n",
        "import xgboost as xgb\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "\n",
        "# Optimizasyon\n",
        "import optuna\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "metadata": {
        "id": "G5-lWpdovt28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Abmn0/emlak_dataset.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdYrjcR1vwFI",
        "outputId": "a4b5f00b-80d3-49e6-e797-e0ad76c0b030",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'emlak_dataset' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"emlak_dataset/veri.csv\")"
      ],
      "metadata": {
        "id": "gXDiY8BDvx91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(index=range(2122, 2142))  # İngilizce satırlar şimdilik silindi"
      ],
      "metadata": {
        "id": "e6nG-KEBvzWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retro Synthwave paleti ve global stil ayarları\n",
        "def set_synthwave_palette(style=\"whitegrid\", context=\"notebook\", font_family=\"sans-serif\"):\n",
        "    palette = ['#f72585', '#b5179e', '#7209b7', '#560bad', '#480ca8',\n",
        "               '#3a0ca3', '#3f37c9', '#4361ee', '#4895ef', '#4cc9f0']\n",
        "\n",
        "    sns.set_palette(palette)\n",
        "    sns.set_style(style)\n",
        "    sns.set_context(context)\n",
        "\n",
        "    # Matplotlib global ayarları\n",
        "    plt.rcParams.update({\n",
        "        'axes.titlepad': 20,\n",
        "        'axes.titlesize': 14,\n",
        "        'axes.labelsize': 12,\n",
        "        'font.family': font_family,\n",
        "        'figure.autolayout': True,\n",
        "        'axes.edgecolor': '#3a0ca3',  # Koyu mor çerçeve\n",
        "        'axes.facecolor': '#ffffff',  # Beyaz arka plan\n",
        "        'figure.facecolor': '#ffffff',  # Beyaz figür arka planı\n",
        "        'axes.labelcolor': '#3a0ca3',  # Koyu mor etiketler\n",
        "        'axes.titlecolor': '#3a0ca3',  # Koyu mor başlık\n",
        "        'xtick.color': '#3a0ca3',  # Koyu mor tick etiketleri\n",
        "        'ytick.color': '#3a0ca3',\n",
        "        'grid.color': '#4cc9f0',  # Açık mavi grid\n",
        "        'grid.alpha': 0.5\n",
        "    })\n",
        "\n",
        "    return palette\n",
        "\n",
        "# Global ayarları uygula\n",
        "palette = set_synthwave_palette()"
      ],
      "metadata": {
        "id": "wHcf-YJyv0X0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Hiç değeri olmayan sütunları silen fonksiyon\n",
        "def remove_empty_columns(df):\n",
        "    empty_cols = [col for col in df.columns if df[col].isna().all()]\n",
        "\n",
        "    df = df.drop(columns=empty_cols)\n",
        "    return df\n",
        "\n",
        "# 2. Tek çeşit değer içeren sütunları silen fonkisyon\n",
        "def remove_single_value_columns(df):\n",
        "    single_value_cols = []\n",
        "    for col in df.columns:\n",
        "        unique_values = df[col].dropna().unique()\n",
        "        if len(unique_values) <= 1:\n",
        "            single_value_cols.append(col)\n",
        "\n",
        "    df = df.drop(columns=single_value_cols)\n",
        "\n",
        "    #Değer varsa 1 yoksa 0\n",
        "    df['housingComplex'] = df['housingComplex'].notnull().astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 3. Telefon numaralarını işleyen fonksiyon\n",
        "def process_phone_numbers(df):\n",
        "    if 'descriptionPhoneNumbers' in df.columns:\n",
        "        df['PhoneNumberPlusFlag'] = df['descriptionPhoneNumbers'].apply(lambda x: 1 if pd.notna(x) and '+' in str(x) else 0)\n",
        "    return df\n",
        "\n",
        "# 4. Belirtilen sütunları silen fonksiyon\n",
        "def remove_columns(df):\n",
        "    columns_to_drop = ['title','description','currency','contact','images','mapLocation','listingUpdatedDate','land','timeShareName'\n",
        "                       'deposit','detailUrl','firmUser','category','videoUrl','featuringProducts','whatsAppNumber','virtualTour',\n",
        "                       'realtyIdentificationNo','listingId.1','realtyId\tno','descriptionPhoneNumbers', 'detailDescription','deposit','landRegisterName']\n",
        "    existing_columns = [col for col in columns_to_drop if col in df.columns]\n",
        "\n",
        "    df.drop(columns=existing_columns, inplace=True)\n",
        "    return df\n",
        "\n",
        "# 5. Attributes özelliğini sütunlara ayıran ve oluşan sütunlara eşik değer kontrolü sağlayan fonksiyon\n",
        "def process_attributes(df, min_feature_count=100):\n",
        "    feature_counts = defaultdict(int)\n",
        "    row_features = {}\n",
        "\n",
        "    # Özellikleri toplama\n",
        "    for idx, attr_str in df['attributes'].items():\n",
        "        features = set()\n",
        "        if pd.isna(attr_str):\n",
        "            row_features[idx] = features\n",
        "            continue\n",
        "\n",
        "        data = ast.literal_eval(attr_str) if isinstance(attr_str, str) else attr_str\n",
        "\n",
        "        def collect_features(obj):\n",
        "            if isinstance(obj, dict):\n",
        "                if 'name' in obj:\n",
        "                    feature = obj['name']\n",
        "                    features.add(feature)\n",
        "                    feature_counts[feature] += 1\n",
        "                for v in obj.values():\n",
        "                    collect_features(v)\n",
        "            elif isinstance(obj, list):\n",
        "                for item in obj:\n",
        "                    collect_features(item)\n",
        "\n",
        "        collect_features(data)\n",
        "        row_features[idx] = features\n",
        "\n",
        "    # Filtrelenmiş özellikleri seçme\n",
        "    filtered_features = {f: f\"attr_{f}\" for f, count in feature_counts.items() if count >= min_feature_count}\n",
        "    print(f\"Toplam {len(feature_counts)} özellik bulundu, {len(filtered_features)} tanesi {min_feature_count} eşiğini geçti.\")\n",
        "\n",
        "    # Yeni sütunları oluşturma\n",
        "    new_columns = pd.DataFrame(0, index=df.index, columns=filtered_features.values())\n",
        "    new_columns['total_features'] = 0\n",
        "\n",
        "    for idx, features in row_features.items():\n",
        "        valid_features = [f for f in features if f in filtered_features]\n",
        "        for feature in valid_features:\n",
        "            new_columns.at[idx, filtered_features[feature]] = 1\n",
        "        new_columns.at[idx, 'total_features'] = len(valid_features)\n",
        "\n",
        "    # Dataframe'i birleştirme\n",
        "    df = pd.concat([df.drop(columns=['attributes']), new_columns], axis=1)\n",
        "    return df\n",
        "\n",
        "\n",
        "# 6. firm sütununda 'inşaat' kelimesi geçenleri işaretleme\n",
        "def process_firm(df):\n",
        "    df['insaat_var_mi'] = df['firm'].fillna(\"\").str.lower().apply(\n",
        "        lambda x: 1 if any(kelime in x for kelime in ['inşaat', 'insaat', 'ınşaat']) else 0\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# 7. sqm sütununu kategorilere ayırıp one-hot encode etme ve eşik kontrolü\n",
        "def process_sqm(df):\n",
        "    def extract_sqm(json_str):\n",
        "        data = json.loads(json_str.replace(\"'\", '\"'))  # JSON string ise düzelt\n",
        "        net = data.get('netSqm', None)\n",
        "        gross = data.get('grossSqm', None)\n",
        "\n",
        "        # gross listeyse ilkini al\n",
        "        if isinstance(gross, list):\n",
        "            gross = gross[0] if gross else None\n",
        "\n",
        "        return pd.Series({'net': net, 'gross': gross})\n",
        "\n",
        "    extracted = df['sqm'].apply(extract_sqm)\n",
        "    df = pd.concat([df, extracted], axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 8. rental sütunu fonksiyonu\n",
        "def process_rental_sub(df):\n",
        "    def get_amount(json_str):\n",
        "        if not isinstance(json_str, str):\n",
        "            return None\n",
        "        try:\n",
        "            data = json.loads(json_str.replace(\"'\", '\"'))  # Tek tırnakları düzelt\n",
        "            return data.get('amount', None)\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "    df['rental_amount'] = df['rental'].apply(get_amount)\n",
        "    df['subCategory'] = df['subCategory'].apply(lambda x: json.loads(x).get('typeName', None) if isinstance(x, str) else None)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 9. redirectLink fosnkiyonu\n",
        "def process_redirectLink(df):\n",
        "\n",
        "    def extract_subcategory(link):\n",
        "        match = re.search(r'\"linkedSubcategoryUrl\":\"(.*?)\"', str(link))\n",
        "        return match.group(1) if match else None\n",
        "\n",
        "    # Alt kategori sütununu oluştur\n",
        "    df['Subcategory'] = df['redirectLink'].apply(extract_subcategory)\n",
        "\n",
        "    # One-hot encoding işlemi\n",
        "    df = pd.get_dummies(df, columns=['Subcategory'], prefix='Subcat')\n",
        "\n",
        "    return df\n",
        "\n",
        "# 10. date ler için olan fonskiyon\n",
        "def process_dates(df):\n",
        "    # Tarih sütunlarını timezone-naive datetime formatına çevir\n",
        "    df['createdDate'] = pd.to_datetime(df['createdDate'], utc=True).dt.tz_localize(None)\n",
        "    df['updatedDate'] = pd.to_datetime(df['updatedDate'], utc=True).dt.tz_localize(None)\n",
        "\n",
        "    # Sadece gün, ay ve yıl bilgilerini karşılaştır (saat kısmını at)\n",
        "    df['sameDayUpdate'] = (df['createdDate'].dt.date == df['updatedDate'].dt.date).astype(int)\n",
        "\n",
        "    # Sütun sırasını düzenle - sameDayUpdate sütununu createdDate ve updatedDate sütunlarının yanına taşı\n",
        "    cols = list(df.columns)\n",
        "    created_idx = cols.index('createdDate')\n",
        "    updated_idx = cols.index('updatedDate')\n",
        "    last_date_idx = max(created_idx, updated_idx)\n",
        "\n",
        "    # sameDayUpdate sütununu son tarih sütunundan sonraki pozisyona yerleştir\n",
        "    cols.remove('sameDayUpdate')\n",
        "    cols.insert(last_date_idx + 1, 'sameDayUpdate')\n",
        "\n",
        "    # Sütunları yeniden düzenle\n",
        "    df = df[cols]\n",
        "\n",
        "    return df\n",
        "\n",
        "# 11. ilgili sütunlarda name-count değerlerini çekme ve önceki sütunları silme\n",
        "def extract_values(df):\n",
        "    def safe_eval(json_str):\n",
        "        try:\n",
        "            return ast.literal_eval(json_str)\n",
        "        except Exception:\n",
        "            return None  # Değerlendirilemeyenler için None döndür\n",
        "\n",
        "    def extract_from_row(json_str, keys):\n",
        "        data = safe_eval(json_str)\n",
        "\n",
        "        if isinstance(data, dict):\n",
        "            return {key: data.get(key, None) for key in keys}\n",
        "\n",
        "        elif isinstance(data, list):\n",
        "            extracted = {\n",
        "                key: [item.get(key, None) for item in data if isinstance(item, dict)]\n",
        "                for key in keys\n",
        "            }\n",
        "\n",
        "            for key in extracted:\n",
        "                values = extracted[key]\n",
        "                if all(isinstance(v, int) for v in values):\n",
        "                    extracted[key] = \", \".join(map(str, values))\n",
        "                elif all(isinstance(v, str) for v in values):\n",
        "                    extracted[key] = \", \".join(values)\n",
        "                else:\n",
        "                    extracted[key] = \", \".join(map(str, values))\n",
        "\n",
        "            return extracted\n",
        "\n",
        "        return {key: None for key in keys}\n",
        "\n",
        "    name_columns = [\"areas\", \"district\", \"county\", \"residence\", \"heating\",\n",
        "                    \"buildState\", \"usage\", \"credit\", \"barter\"]\n",
        "\n",
        "    for col in name_columns:\n",
        "        extracted = df[col].astype(str).apply(lambda x: extract_from_row(x, [\"name\"]))\n",
        "        df[f\"{col}_name\"] = extracted.apply(lambda x: x[\"name\"])\n",
        "        df.drop(columns=[col], inplace=True)\n",
        "\n",
        "    extracted_floor = df[\"floor\"].astype(str).apply(lambda x: extract_from_row(x, [\"name\", \"count\"]))\n",
        "    df[\"floor_name\"] = extracted_floor.apply(lambda x: x[\"name\"])\n",
        "    df[\"floor_count\"] = extracted_floor.apply(lambda x: x[\"count\"])\n",
        "    df.drop(columns=[\"floor\"], inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 12. Sides Sütunu İçin Bölgelere ayırma\n",
        "\n",
        "def sides_process(df):\n",
        "    df['sides'] = df['sides'].astype(str).str.lower()\n",
        "\n",
        "    df['kuzey'] = df['sides'].apply(lambda x: 1 if 'kuzey' in x else 0)\n",
        "    df['güney'] = df['sides'].apply(lambda x: 1 if 'güney' in x else 0)\n",
        "    df['doğu']  = df['sides'].apply(lambda x: 1 if 'doğu'  in x else 0)\n",
        "    df['batı']  = df['sides'].apply(lambda x: 1 if 'batı'  in x else 0)\n",
        "\n",
        "    def extract_amount(fee):\n",
        "        if pd.isna(fee):\n",
        "            return 0.0\n",
        "        fee_dict = ast.literal_eval(fee)\n",
        "        return float(fee_dict.get('amount', 0))\n",
        "\n",
        "    df['amount'] = df['fee'].apply(extract_amount)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 13. İşlenmiş sütunları silen fonksiyon\n",
        "def delete_columns(df):\n",
        "    silinecek_sutunlar = [\n",
        "        'realtyId', 'no', 'startDate', 'endDate', 'createdDate', 'updatedDate',\n",
        "        'sqm', 'fuel', 'build', 'redirectLink', 'firm', 'fee', 'sides','rental'\n",
        "    ]\n",
        "    df.drop(columns=[col for col in silinecek_sutunlar if col in df.columns], inplace=True)\n",
        "    return df\n",
        "\n",
        "def fill_missing_values(df):\n",
        "\n",
        "    # Sayısal sütunlar\n",
        "    numerical_columns = ['age', 'searchScore', 'total_features', 'net', 'gross', 'amount', 'rental_amount']\n",
        "\n",
        "    # Sayısal sütunlardaki eksik (NaN) veya 0 olan değerleri -999 ile doldur\n",
        "    for col in numerical_columns:\n",
        "        df[col] = df[col].apply(lambda x: -999 if pd.isna(x) or x == 0 else x)\n",
        "\n",
        "    # Diğer tüm sütunlar (kategorik sütunlar)\n",
        "    for col in df.columns:\n",
        "        if col not in numerical_columns:\n",
        "            df[col] = df[col].fillna('NaN').apply(lambda x: 'NaN' if pd.isna(x) else x)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 14. Belirtilen sütunları encode etme ve oluşan sütunları belli bir eşik değerine göre eleme\n",
        "def encode_columns(df, threshold=0.05):\n",
        "    # Kopya oluştur (orijinal veriyi koru)\n",
        "    df = df.copy()\n",
        "\n",
        "    # SADECE encode edilecek sütunları string'e çevir\n",
        "    encode_columns = ['room', 'livingRoom', 'bathRoom', 'floor_count',  # label_columns\n",
        "                     'subCategory', 'roomAndLivingRoom', 'registerState',  # one_hot_columns\n",
        "                     'areas_name', 'district_name', 'county_name', 'residence_name',\n",
        "                     'heating_name', 'buildState_name', 'usage_name',\n",
        "                     'credit_name', 'barter_name', 'floor_name',\n",
        "                     'authorizedRealtor', 'furnished']\n",
        "\n",
        "    # Sadece belirtilen sütunları string yap (diğerlerine dokunma)\n",
        "    for col in encode_columns:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(str)\n",
        "\n",
        "    # Label Encoding\n",
        "    le = LabelEncoder()\n",
        "    label_columns = ['room', 'livingRoom', 'bathRoom', 'floor_count']\n",
        "    for col in label_columns:\n",
        "        if col in df.columns:\n",
        "            df[col] = le.fit_transform(df[col])\n",
        "\n",
        "    # One-Hot Encoding\n",
        "    one_hot_columns = ['subCategory', 'roomAndLivingRoom', 'registerState',\n",
        "                      'areas_name', 'district_name', 'county_name', 'residence_name',\n",
        "                      'heating_name', 'buildState_name', 'usage_name',\n",
        "                      'credit_name', 'barter_name', 'floor_name',\n",
        "                      'authorizedRealtor', 'furnished']\n",
        "\n",
        "    df = pd.get_dummies(df, columns=one_hot_columns, drop_first=True)\n",
        "\n",
        "    # Eşik değer kontrolü (SADECE one-hot ile oluşan yeni sütunlara uygula)\n",
        "    original_columns = df.columns\n",
        "    new_columns = [col for col in df.columns if col not in original_columns]\n",
        "    for col in new_columns:\n",
        "        value_counts = df[col].value_counts(normalize=True)\n",
        "        if value_counts.iloc[0] <= threshold:\n",
        "            df.drop(columns=[col], inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 15. Belirtilen sütunları scale etme\n",
        "def scale_selected_columns(df):\n",
        "    numeric_columns = ['age', 'searchScore', 'total_features', 'amount', 'rental_amount']\n",
        "\n",
        "    # Min-Max Scaler'ı başlatıyoruz\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    # Sayısal sütunları ölçeklendiriyoruz\n",
        "    df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
        "\n",
        "    return df\n",
        "\n",
        "# 16. True/False string değerlerini bool veri tipine dönüştürme\n",
        "def convert_to_bool(df):\n",
        "\n",
        "    # Sadece object/string tipindeki sütunları al\n",
        "    str_cols = df.select_dtypes(include='object').columns\n",
        "\n",
        "    for col in str_cols:\n",
        "        unique_vals = df[col].dropna().unique()\n",
        "        # Sadece \"True\" ve \"False\" içeriyorsa\n",
        "        if set(unique_vals).issubset({\"True\", \"False\"}):\n",
        "            df[col] = df[col].map({\"True\": True, \"False\": False})\n",
        "\n",
        "    return df\n",
        "\n",
        "# Sütun isimlerini kontrol etme ve temizleme\n",
        "def clean_column_names(df):\n",
        "    # Sütun isimlerini string'e çevir ve geçersiz karakterleri değiştir\n",
        "    df.columns = [str(col).replace('[', '_').replace(']', '_').replace('<', '_').replace('>', '_') for col in df.columns]\n",
        "    return df\n",
        "\n",
        "# 17. Tüm işlemleri birleştiren ana fonksiyon\n",
        "def process_dataframe_complete(df):\n",
        "    processed_df = df.copy() # Üst üste çalıştırdığımızda veri kaybı sorunu yaşamamak için kopyasında işlem yapıyoruz\n",
        "\n",
        "    processed_df = remove_empty_columns(processed_df)\n",
        "    processed_df = remove_single_value_columns(processed_df)\n",
        "    processed_df = process_phone_numbers(processed_df)\n",
        "    processed_df = remove_columns(processed_df)\n",
        "    processed_df = process_attributes(processed_df, min_feature_count=100)\n",
        "    processed_df = process_firm(processed_df)\n",
        "    processed_df = process_redirectLink(processed_df)\n",
        "    processed_df = extract_values(processed_df)\n",
        "    processed_df = process_dates(processed_df)\n",
        "    processed_df = process_sqm(processed_df)\n",
        "    processed_df = sides_process(processed_df)\n",
        "    processed_df = process_rental_sub(processed_df)\n",
        "    processed_df = delete_columns(processed_df)\n",
        "    processed_df = scale_selected_columns(processed_df)\n",
        "    processed_df = fill_missing_values(processed_df)\n",
        "    processed_df = encode_columns(processed_df, threshold=0.2)\n",
        "    processed_df = convert_to_bool(processed_df)\n",
        "    processed_df = clean_column_names(processed_df)\n",
        "\n",
        "    return processed_df\n",
        "\n",
        "# Tüm fonksiyonları çalıştır\n",
        "processed_df = process_dataframe_complete(df)\n",
        "\n",
        "#Bu sütunu koruyoruz daha sonra tahmin edeceğiz\n",
        "room_col = processed_df['room']\n",
        "housing_col = processed_df['housingComplex']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hqlni_FYv2TB",
        "outputId": "c503cd2d-38e9-41e3-a2e5-12fb0fc75ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toplam 246 özellik bulundu, 71 tanesi 100 eşiğini geçti.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBRfj7YNYnxb",
        "outputId": "279794f2-40b1-4d31-f8b3-5061b8492e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 2140 entries, 0 to 2159\n",
            "Columns: 545 entries, listingId to furnished_True\n",
            "dtypes: bool(453), float64(5), int64(86), object(1)\n",
            "memory usage: 2.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ÖN İŞLEME SONRASI 545 SÜTUN İLE EĞİTİM"
      ],
      "metadata": {
        "id": "Tf5UWHfaYi2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef, roc_auc_score, classification_report\n",
        "import xgboost as xgb\n",
        "import optuna\n",
        "\n",
        "def run_xgboost_model(\n",
        "    optuna_enabled=False,\n",
        "    test_size=100,\n",
        "    n_splits=5,\n",
        "    random_state=42,\n",
        "    n_trials=10,\n",
        "    output_excel='test_predictions.xlsx'\n",
        "):\n",
        "\n",
        "    # Hedef ve özellik sütunlarını belirleme\n",
        "    target_column = 'housingComplex'\n",
        "    if target_column not in processed_df.columns:\n",
        "        raise ValueError(\"processed_df'de 'housingComplex' sütunu bulunamadı.\")\n",
        "\n",
        "    # Özellik sütunlarını belirle, 'listingId' sütununu hariç tut\n",
        "    feature_columns = [col for col in processed_df.columns if col not in [target_column, 'listingId']]\n",
        "\n",
        "    # Özellik sütunlarının veri tiplerini kontrol et\n",
        "    invalid_columns = []\n",
        "    for col in feature_columns:\n",
        "        if processed_df[col].dtype not in ['int64', 'float64', 'bool', 'category']:\n",
        "            invalid_columns.append(col)\n",
        "    if invalid_columns:\n",
        "        raise ValueError(\n",
        "            f\"Geçersiz veri tipleri tespit edildi. XGBoost sadece int, float, bool veya category türlerini destekler. \"\n",
        "            f\"Geçersiz sütunlar: {invalid_columns}\"\n",
        "        )\n",
        "\n",
        "    # Sınıf frekanslarını kontrol et\n",
        "    class_counts = processed_df[target_column].value_counts()\n",
        "    print(\"Sınıf frekansları:\\n\", class_counts)\n",
        "\n",
        "    # Veri setini ayırma\n",
        "    train_df, test_df = train_test_split(\n",
        "        processed_df, test_size=test_size, random_state=random_state, stratify=processed_df[target_column]\n",
        "    )\n",
        "\n",
        "    # Eğitim ve test verileri\n",
        "    X = train_df[feature_columns]\n",
        "    y = train_df[target_column]\n",
        "    X_test_final = test_df[feature_columns]\n",
        "    y_test_final = test_df[target_column]\n",
        "\n",
        "    # scale_pos_weight hesaplama\n",
        "    scale_pos_weight = sum(y == 0) / sum(y == 1)\n",
        "    print(f\"scale_pos_weight: {scale_pos_weight:.4f}\")\n",
        "\n",
        "    # Varsayılan model parametreleri\n",
        "    default_params = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'eta': 0.1,\n",
        "        'max_depth': 6,\n",
        "        'n_estimators': 1000,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.8,\n",
        "        'min_child_weight': 1,\n",
        "        'gamma': 0,\n",
        "        'reg_alpha': 0,\n",
        "        'reg_lambda': 1,\n",
        "        'random_state': random_state,\n",
        "        'eval_metric': 'auc',\n",
        "        'early_stopping_rounds': 30,\n",
        "        'scale_pos_weight': scale_pos_weight\n",
        "    }\n",
        "\n",
        "    # Optuna ile hiperparametre optimizasyonu\n",
        "    if optuna_enabled:\n",
        "        def objective(trial):\n",
        "            optuna_params = {\n",
        "                'eta': trial.suggest_float('eta', 0.01, 0.3, log=True),\n",
        "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
        "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "                'gamma': trial.suggest_float('gamma', 0, 5),\n",
        "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
        "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
        "                'objective': 'binary:logistic',\n",
        "                'random_state': random_state,\n",
        "                'eval_metric': 'auc',\n",
        "                'early_stopping_rounds': 30,\n",
        "                'scale_pos_weight': scale_pos_weight\n",
        "            }\n",
        "\n",
        "            # Çapraz doğrulama\n",
        "            kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "            f1_scores = []\n",
        "\n",
        "            for train_index, test_index in kf.split(X):\n",
        "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "                X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "                    X_train, y_train, test_size=0.2, random_state=random_state, stratify=y_train\n",
        "                )\n",
        "\n",
        "                model = xgb.XGBClassifier(**optuna_params)\n",
        "                model.fit(\n",
        "                    X_train_split,\n",
        "                    y_train_split,\n",
        "                    eval_set=[(X_val, y_val)],\n",
        "                    verbose=False\n",
        "                )\n",
        "\n",
        "                y_pred = model.predict(X_test)  # F1 skoru için sınıf tahminleri\n",
        "                f1_scores.append(f1_score(y_test, y_pred))\n",
        "\n",
        "            return np.mean(f1_scores)\n",
        "\n",
        "        # Optuna çalıştır\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(objective, n_trials=n_trials)\n",
        "        best_params = study.best_params\n",
        "        best_params.update({\n",
        "            'objective': 'binary:logistic',\n",
        "            'random_state': random_state,\n",
        "            'eval_metric': 'auc',\n",
        "            'early_stopping_rounds': 30,\n",
        "            'scale_pos_weight': scale_pos_weight\n",
        "        })\n",
        "        print(\"En iyi parametreler:\", best_params)\n",
        "        model_params = best_params\n",
        "    else:\n",
        "        model_params = default_params\n",
        "\n",
        "    # Çapraz doğrulama\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    accuracy_scores, f1_scores, mcc_scores, auc_scores = [], [], [], []\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        # Eğitim ve doğrulama setleri\n",
        "        X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "            X_train, y_train, test_size=0.2, random_state=random_state, stratify=y_train\n",
        "        )\n",
        "\n",
        "        # Model eğitimi\n",
        "        xgb_model = xgb.XGBClassifier(**model_params)\n",
        "        xgb_model.fit(\n",
        "            X_train_split,\n",
        "            y_train_split,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            verbose=False\n",
        "        )\n",
        "\n",
        "        # Tahmin\n",
        "        y_pred = xgb_model.predict(X_test)\n",
        "        y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        # Metrikler\n",
        "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "        f1_scores.append(f1_score(y_test, y_pred))\n",
        "        mcc_scores.append(matthews_corrcoef(y_test, y_pred))\n",
        "        auc_scores.append(roc_auc_score(y_test, y_pred_proba))\n",
        "\n",
        "        # Kat sonuçları\n",
        "        print(f\"Fold {fold}:\")\n",
        "        print(f\"  Doğruluk: {accuracy_scores[-1]:.4f}\")\n",
        "        print(f\"  F1 Skoru: {f1_scores[-1]:.4f}\")\n",
        "        print(f\"  MCC: {mcc_scores[-1]:.4f}\")\n",
        "        print(f\"  AUC-ROC: {auc_scores[-1]:.4f}\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "    # Ortalama metrikler\n",
        "    print(\"5 Katlı Çapraz Doğrulama Ortalama Sonuçları:\")\n",
        "    print(f\"Ortalama Doğruluk: {np.mean(accuracy_scores):.4f} ± {np.std(accuracy_scores):.4f}\")\n",
        "    print(f\"Ortalama F1 Skoru: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n",
        "    print(f\"Ortalama MCC: {np.mean(mcc_scores):.4f} ± {np.std(mcc_scores):.4f}\")\n",
        "    print(f\"Ortalama AUC-ROC: {np.mean(auc_scores):.4f} ± {np.std(auc_scores):.4f}\")\n",
        "\n",
        "    # Nihai model\n",
        "    xgb_model_final = xgb.XGBClassifier(**model_params)\n",
        "    xgb_model_final.fit(X, y, eval_set=[(X, y)], verbose=False)\n",
        "\n",
        "    # Nihai test tahminleri\n",
        "    y_pred_final = xgb_model_final.predict(X_test_final)\n",
        "    y_pred_proba_final = xgb_model_final.predict_proba(X_test_final)[:, 1]\n",
        "\n",
        "    # Nihai metrikler\n",
        "    print(\"\\nAyrılan Test Seti Üzerinde Nihai Sonuçlar:\")\n",
        "    print(f\"Doğruluk: {accuracy_score(y_test_final, y_pred_final):.4f}\")\n",
        "    print(f\"F1 Skoru: {f1_score(y_test_final, y_pred_final):.4f}\")\n",
        "    print(f\"MCC: {matthews_corrcoef(y_test_final, y_pred_final):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_test_final, y_pred_proba_final):.4f}\")\n",
        "\n",
        "    # Sınıflandırma raporu\n",
        "    print(\"\\nSınıflandırma Raporu (Test Seti):\")\n",
        "    print(classification_report(y_test_final, y_pred_final))\n",
        "\n",
        "    # Tahminleri kaydet\n",
        "    results_df = pd.DataFrame({\n",
        "        f'Gerçek {target_column}': y_test_final,\n",
        "        f'Tahmin Edilen {target_column}': y_pred_final\n",
        "    })\n",
        "    results_df.to_excel(output_excel, index=False)\n",
        "    print(f\"\\nTahminler ve gerçek değerler '{output_excel}' dosyasına kaydedildi.\")\n",
        "\n",
        "    return results_df"
      ],
      "metadata": {
        "id": "d5b3yLi0v9f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPTUNA KAPALI DEFAULT PARAMETRELERLE"
      ],
      "metadata": {
        "id": "t2WPygX8YzlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_xgboost = run_xgboost_model(optuna_enabled=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHI13YXvzZHJ",
        "outputId": "938a2ef2-2573-41cb-f314-0f1d85ff4cd0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sınıf frekansları:\n",
            " housingComplex\n",
            "0    1748\n",
            "1     392\n",
            "Name: count, dtype: int64\n",
            "scale_pos_weight: 4.4545\n",
            "Fold 1:\n",
            "  Doğruluk: 0.8137\n",
            "  F1 Skoru: 0.5422\n",
            "  MCC: 0.4287\n",
            "  AUC-ROC: 0.8614\n",
            "--------------------------------------------------\n",
            "Fold 2:\n",
            "  Doğruluk: 0.8015\n",
            "  F1 Skoru: 0.5318\n",
            "  MCC: 0.4105\n",
            "  AUC-ROC: 0.8486\n",
            "--------------------------------------------------\n",
            "Fold 3:\n",
            "  Doğruluk: 0.8260\n",
            "  F1 Skoru: 0.5590\n",
            "  MCC: 0.4606\n",
            "  AUC-ROC: 0.8720\n",
            "--------------------------------------------------\n",
            "Fold 4:\n",
            "  Doğruluk: 0.8431\n",
            "  F1 Skoru: 0.6049\n",
            "  MCC: 0.5071\n",
            "  AUC-ROC: 0.8997\n",
            "--------------------------------------------------\n",
            "Fold 5:\n",
            "  Doğruluk: 0.8284\n",
            "  F1 Skoru: 0.5783\n",
            "  MCC: 0.4832\n",
            "  AUC-ROC: 0.8609\n",
            "--------------------------------------------------\n",
            "5 Katlı Çapraz Doğrulama Ortalama Sonuçları:\n",
            "Ortalama Doğruluk: 0.8225 ± 0.0141\n",
            "Ortalama F1 Skoru: 0.5632 ± 0.0261\n",
            "Ortalama MCC: 0.4580 ± 0.0351\n",
            "Ortalama AUC-ROC: 0.8685 ± 0.0173\n",
            "\n",
            "Ayrılan Test Seti Üzerinde Nihai Sonuçlar:\n",
            "Doğruluk: 0.8500\n",
            "F1 Skoru: 0.5455\n",
            "MCC: 0.4592\n",
            "AUC-ROC: 0.8293\n",
            "\n",
            "Sınıflandırma Raporu (Test Seti):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.93      0.91        82\n",
            "           1       0.60      0.50      0.55        18\n",
            "\n",
            "    accuracy                           0.85       100\n",
            "   macro avg       0.75      0.71      0.73       100\n",
            "weighted avg       0.84      0.85      0.84       100\n",
            "\n",
            "\n",
            "Tahminler ve gerçek değerler 'test_predictions.xlsx' dosyasına kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPTUNA AÇIK HİPER PARAMETRE OPTİMİZASYONU İLE"
      ],
      "metadata": {
        "id": "WK6P-B26Yx3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_xgboost = run_xgboost_model(optuna_enabled=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORIG0GivxQK1",
        "outputId": "18284973-18d1-446e-bc75-9cdaa3627972",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 07:13:33,411] A new study created in memory with name: no-name-41ecb454-5795-474b-a13c-4f249769d5bc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sınıf frekansları:\n",
            " housingComplex\n",
            "0    1748\n",
            "1     392\n",
            "Name: count, dtype: int64\n",
            "scale_pos_weight: 4.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 07:13:43,757] Trial 0 finished with value: 0.5701222775354255 and parameters: {'eta': 0.02748685173861914, 'max_depth': 6, 'n_estimators': 852, 'subsample': 0.6342722720359109, 'colsample_bytree': 0.6694338912056643, 'min_child_weight': 3, 'gamma': 2.6394148445433534, 'reg_alpha': 0.2402487729649172, 'reg_lambda': 2.6386349653342247}. Best is trial 0 with value: 0.5701222775354255.\n",
            "[I 2025-05-07 07:13:53,312] Trial 1 finished with value: 0.5520806267383115 and parameters: {'eta': 0.06910048301340528, 'max_depth': 6, 'n_estimators': 567, 'subsample': 0.7262157111134264, 'colsample_bytree': 0.607258524141215, 'min_child_weight': 10, 'gamma': 4.560988598463877, 'reg_alpha': 9.613502347241676, 'reg_lambda': 3.4143123154955637}. Best is trial 0 with value: 0.5701222775354255.\n",
            "[I 2025-05-07 07:13:59,383] Trial 2 finished with value: 0.5689068431278167 and parameters: {'eta': 0.13469044716396217, 'max_depth': 6, 'n_estimators': 810, 'subsample': 0.9675075368483225, 'colsample_bytree': 0.8169695267400847, 'min_child_weight': 6, 'gamma': 4.780243136045469, 'reg_alpha': 3.3432236577501584, 'reg_lambda': 9.905655909703658}. Best is trial 0 with value: 0.5701222775354255.\n",
            "[I 2025-05-07 07:14:08,391] Trial 3 finished with value: 0.5635944480063156 and parameters: {'eta': 0.1230296676795786, 'max_depth': 7, 'n_estimators': 107, 'subsample': 0.6509044339021317, 'colsample_bytree': 0.6139611551523149, 'min_child_weight': 8, 'gamma': 0.5559107957094772, 'reg_alpha': 7.866448032216445, 'reg_lambda': 1.8057933156488237}. Best is trial 0 with value: 0.5701222775354255.\n",
            "[I 2025-05-07 07:14:15,967] Trial 4 finished with value: 0.5823805088838709 and parameters: {'eta': 0.213946795254392, 'max_depth': 9, 'n_estimators': 603, 'subsample': 0.9787661329142636, 'colsample_bytree': 0.6249252087217333, 'min_child_weight': 2, 'gamma': 2.361839334144085, 'reg_alpha': 0.47947142529328746, 'reg_lambda': 9.704630762715713}. Best is trial 4 with value: 0.5823805088838709.\n",
            "[I 2025-05-07 07:14:23,392] Trial 5 finished with value: 0.5544118153233526 and parameters: {'eta': 0.14938575414092423, 'max_depth': 3, 'n_estimators': 117, 'subsample': 0.8758199268658167, 'colsample_bytree': 0.677576138295599, 'min_child_weight': 8, 'gamma': 1.1961174213890435, 'reg_alpha': 7.527532470456313, 'reg_lambda': 5.332490072295576}. Best is trial 4 with value: 0.5823805088838709.\n",
            "[I 2025-05-07 07:14:36,149] Trial 6 finished with value: 0.5732443283983457 and parameters: {'eta': 0.023941480161764665, 'max_depth': 5, 'n_estimators': 893, 'subsample': 0.9456325415146023, 'colsample_bytree': 0.9854921821807189, 'min_child_weight': 6, 'gamma': 3.6959827486021917, 'reg_alpha': 2.8065373330210805, 'reg_lambda': 1.6272057212027224}. Best is trial 4 with value: 0.5823805088838709.\n",
            "[I 2025-05-07 07:14:46,104] Trial 7 finished with value: 0.5704183413974309 and parameters: {'eta': 0.04750839710516688, 'max_depth': 5, 'n_estimators': 851, 'subsample': 0.768324223440488, 'colsample_bytree': 0.9571232892773985, 'min_child_weight': 5, 'gamma': 1.6856206603864394, 'reg_alpha': 3.012340814803344, 'reg_lambda': 7.516096517430579}. Best is trial 4 with value: 0.5823805088838709.\n",
            "[I 2025-05-07 07:14:55,678] Trial 8 finished with value: 0.5721574508462188 and parameters: {'eta': 0.12464332415878271, 'max_depth': 6, 'n_estimators': 841, 'subsample': 0.8315788343313909, 'colsample_bytree': 0.7447285652914043, 'min_child_weight': 8, 'gamma': 3.3251667677247747, 'reg_alpha': 7.526019028069163, 'reg_lambda': 5.745169596604183}. Best is trial 4 with value: 0.5823805088838709.\n",
            "[I 2025-05-07 07:15:05,438] Trial 9 finished with value: 0.5424527529814545 and parameters: {'eta': 0.02569939412873448, 'max_depth': 10, 'n_estimators': 678, 'subsample': 0.5437566466454102, 'colsample_bytree': 0.8960874546449332, 'min_child_weight': 2, 'gamma': 1.711862844946711, 'reg_alpha': 8.464830407377503, 'reg_lambda': 5.944544770589413}. Best is trial 4 with value: 0.5823805088838709.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En iyi parametreler: {'eta': 0.213946795254392, 'max_depth': 9, 'n_estimators': 603, 'subsample': 0.9787661329142636, 'colsample_bytree': 0.6249252087217333, 'min_child_weight': 2, 'gamma': 2.361839334144085, 'reg_alpha': 0.47947142529328746, 'reg_lambda': 9.704630762715713, 'objective': 'binary:logistic', 'random_state': 42, 'eval_metric': 'auc', 'early_stopping_rounds': 30, 'scale_pos_weight': 4.454545454545454}\n",
            "Fold 1:\n",
            "  Doğruluk: 0.8211\n",
            "  F1 Skoru: 0.5731\n",
            "  MCC: 0.4663\n",
            "  AUC-ROC: 0.8779\n",
            "--------------------------------------------------\n",
            "Fold 2:\n",
            "  Doğruluk: 0.7868\n",
            "  F1 Skoru: 0.5672\n",
            "  MCC: 0.4548\n",
            "  AUC-ROC: 0.8348\n",
            "--------------------------------------------------\n",
            "Fold 3:\n",
            "  Doğruluk: 0.8407\n",
            "  F1 Skoru: 0.5806\n",
            "  MCC: 0.4882\n",
            "  AUC-ROC: 0.8675\n",
            "--------------------------------------------------\n",
            "Fold 4:\n",
            "  Doğruluk: 0.8284\n",
            "  F1 Skoru: 0.6196\n",
            "  MCC: 0.5170\n",
            "  AUC-ROC: 0.8922\n",
            "--------------------------------------------------\n",
            "Fold 5:\n",
            "  Doğruluk: 0.8162\n",
            "  F1 Skoru: 0.5714\n",
            "  MCC: 0.4756\n",
            "  AUC-ROC: 0.8573\n",
            "--------------------------------------------------\n",
            "5 Katlı Çapraz Doğrulama Ortalama Sonuçları:\n",
            "Ortalama Doğruluk: 0.8186 ± 0.0179\n",
            "Ortalama F1 Skoru: 0.5824 ± 0.0191\n",
            "Ortalama MCC: 0.4804 ± 0.0213\n",
            "Ortalama AUC-ROC: 0.8659 ± 0.0194\n",
            "\n",
            "Ayrılan Test Seti Üzerinde Nihai Sonuçlar:\n",
            "Doğruluk: 0.8000\n",
            "F1 Skoru: 0.5455\n",
            "MCC: 0.4344\n",
            "AUC-ROC: 0.8462\n",
            "\n",
            "Sınıflandırma Raporu (Test Seti):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.83      0.87        82\n",
            "           1       0.46      0.67      0.55        18\n",
            "\n",
            "    accuracy                           0.80       100\n",
            "   macro avg       0.69      0.75      0.71       100\n",
            "weighted avg       0.84      0.80      0.81       100\n",
            "\n",
            "\n",
            "Tahminler ve gerçek değerler 'test_predictions.xlsx' dosyasına kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RFE İLE ÖZELLİK SEÇİMİ"
      ],
      "metadata": {
        "id": "wkQ96EdrY-CR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import r2_score\n",
        "from itertools import combinations\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# RFE Fonksiyonu (numeric_columns korunuyor)\n",
        "def run_rfe_separately(target_column='price', feature_exclude_columns=['listingId'], protected_columns=None,\n",
        "                       model_params=None, cv=5, step=20, min_features_to_select=70, test_size=0.2,\n",
        "                       random_state=42, min_steps=30):\n",
        "    global processed_df\n",
        "    if protected_columns is None:\n",
        "        protected_columns = []\n",
        "\n",
        "    # Özellikleri seç (hedef ve hariç tutulacak sütunlar hariç)\n",
        "    features = [col for col in processed_df.columns if col != target_column and col not in feature_exclude_columns]\n",
        "    if not features:\n",
        "        raise ValueError(\"Seçilecek özellik bulunamadı. Veri setini kontrol edin.\")\n",
        "\n",
        "    # protected_columns'ın veri setinde mevcut olduğunu kontrol et\n",
        "    protected_columns = [col for col in protected_columns if col in features]\n",
        "    print(f\"Korunacak sütunlar: {protected_columns}\")\n",
        "\n",
        "    X = processed_df[features]\n",
        "    y = processed_df[target_column]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    # Model parametreleri\n",
        "    if model_params is None:\n",
        "        model_params = {\n",
        "            'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'random_state': random_state,\n",
        "            'early_stopping_rounds': 60, 'eta': 0.024, 'max_depth': 5, 'n_estimators': 850,\n",
        "            'subsample': 0.62, 'colsample_bytree': 0.86, 'min_child_weight': 1,\n",
        "            'gamma': 3.5, 'reg_alpha': 7.9, 'reg_lambda': 0.15,\n",
        "            'n_jobs': -1 if not torch.cuda.is_available() else 1, 'verbosity': 0,\n",
        "            'tree_method': 'hist', 'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        }\n",
        "\n",
        "    # İlk model eğitimi\n",
        "    model = xgb.XGBRegressor(**model_params)\n",
        "    model.fit(X_train, y_train, eval_set=[(X_train, y_train)], verbose=False)\n",
        "\n",
        "    # Düşük önemli özellikleri çıkar (protected_columns hariç)\n",
        "    importance = pd.DataFrame({'Feature': X_train.columns, 'Importance': model.feature_importances_})\n",
        "    low_importance_features = importance.sort_values('Importance')[:int(0.3 * len(X_train.columns))]['Feature'].tolist()\n",
        "    low_importance_features = [f for f in low_importance_features if f not in protected_columns]\n",
        "    X_train = X_train.drop(columns=low_importance_features)\n",
        "    X_test = X_test.drop(columns=low_importance_features)\n",
        "\n",
        "    n_features = X_train.shape[1]\n",
        "    remaining_features = list(X_train.columns)\n",
        "    r2_scores = []\n",
        "    selected_features_history = []\n",
        "    step_count = 0\n",
        "\n",
        "    print(f\"Başlangıç Özellik Sayısı: {n_features}\\nRFE Başlıyor...\")\n",
        "\n",
        "    # RFE döngüsü\n",
        "    while n_features > min_features_to_select and step_count < min_steps:\n",
        "        print(f\"{n_features} özellik ile eğitim...\")\n",
        "        X_train_sub = X_train[remaining_features]\n",
        "        kf = KFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
        "        fold_r2 = []\n",
        "\n",
        "        for train_idx, val_idx in kf.split(X_train_sub):\n",
        "            X_tr, X_val = X_train_sub.iloc[train_idx], X_train_sub.iloc[val_idx]\n",
        "            y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "            model = xgb.XGBRegressor(**model_params)\n",
        "            model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
        "            fold_r2.append(r2_score(y_val, model.predict(X_val)))\n",
        "\n",
        "        avg_r2 = np.mean(fold_r2)\n",
        "        r2_scores.append(avg_r2)\n",
        "        selected_features_history.append(remaining_features.copy())\n",
        "        print(f\"Ortalama R²: {avg_r2:.4f}\")\n",
        "\n",
        "        model.fit(X_train_sub, y_train, eval_set=[(X_train_sub, y_train)], verbose=False)\n",
        "        importance = pd.DataFrame({'Feature': remaining_features, 'Importance': model.feature_importances_})\n",
        "        removed_features = importance.sort_values('Importance')[:min(step, len(importance))]['Feature'].tolist()\n",
        "        # protected_columns'ı koru\n",
        "        removed_features = [f for f in removed_features if f not in protected_columns]\n",
        "        remaining_features = [f for f in remaining_features if f not in removed_features]\n",
        "        n_features = len(remaining_features)\n",
        "        step_count += 1\n",
        "\n",
        "    best_features = remaining_features\n",
        "    best_score = r2_scores[-1] if r2_scores else 0\n",
        "\n",
        "    print(f\"\\nRFE Tamamlandı.\\nSon R²: {best_score:.4f}\\nÖzellik sayısı: {len(best_features)}\")\n",
        "\n",
        "    # Final model eğitimi ve test\n",
        "    final_model = xgb.XGBRegressor(**model_params)\n",
        "    final_model.fit(X_train[best_features], y_train, eval_set=[(X_train[best_features], y_train)], verbose=False)\n",
        "    test_preds = final_model.predict(X_test[best_features])\n",
        "    test_r2 = r2_score(y_test, test_preds)\n",
        "    print(f\"Test R²: {test_r2:.4f}\")\n",
        "\n",
        "    # Özellik önemlerini görselleştir ve kaydet\n",
        "    importance = pd.DataFrame({'Feature': best_features, 'Importance': final_model.feature_importances_})\n",
        "    importance = importance.sort_values('Importance', ascending=False)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    importance.head(30).plot(kind='barh', x='Feature', y='Importance')\n",
        "    plt.title('En Önemli 30 Özellik')\n",
        "    plt.xlabel('Özellik Önemi')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('rfe_final_feature_importance.png')\n",
        "    plt.close()\n",
        "\n",
        "    importance.to_csv('rfe_final_feature_importance.csv', index=False)\n",
        "    print(f\"\\nÖzellik önemleri 'rfe_final_feature_importance.csv' dosyasına kaydedildi.\")\n",
        "\n",
        "    # processed_df'yi güncelle\n",
        "    keep_columns = best_features + [target_column] + feature_exclude_columns\n",
        "    processed_df = processed_df[keep_columns]\n",
        "\n",
        "    return best_features\n",
        "\n",
        "# 1. RFE ile özellik seçimi (numeric_columns korunuyor)\n",
        "numeric_columns = ['net', 'gross', 'room', 'bathRoom', 'housingComplex']\n",
        "selected_features = run_rfe_separately(protected_columns=numeric_columns)\n",
        "\n",
        "# 2. RFE sonrası processed_df durumu\n",
        "print(f\"RFE sonrası processed_df sütunları: {list(processed_df.columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 800
        },
        "id": "J2lq2jP53z5q",
        "outputId": "53b78921-89c7-4b97-f50c-9b1ba2704df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Korunacak sütunlar: ['net', 'gross', 'room', 'bathRoom', 'housingComplex']\n",
            "Başlangıç Özellik Sayısı: 381\n",
            "RFE Başlıyor...\n",
            "381 özellik ile eğitim...\n",
            "Ortalama R²: 0.6138\n",
            "361 özellik ile eğitim...\n",
            "Ortalama R²: 0.5911\n",
            "341 özellik ile eğitim...\n",
            "Ortalama R²: 0.6022\n",
            "321 özellik ile eğitim...\n",
            "Ortalama R²: 0.6022\n",
            "301 özellik ile eğitim...\n",
            "Ortalama R²: 0.6071\n",
            "281 özellik ile eğitim...\n",
            "Ortalama R²: 0.6115\n",
            "261 özellik ile eğitim...\n",
            "Ortalama R²: 0.5972\n",
            "241 özellik ile eğitim...\n",
            "Ortalama R²: 0.6071\n",
            "221 özellik ile eğitim...\n",
            "Ortalama R²: 0.6039\n",
            "201 özellik ile eğitim...\n",
            "Ortalama R²: 0.6086\n",
            "181 özellik ile eğitim...\n",
            "Ortalama R²: 0.6066\n",
            "161 özellik ile eğitim...\n",
            "Ortalama R²: 0.5937\n",
            "141 özellik ile eğitim...\n",
            "Ortalama R²: 0.6092\n",
            "121 özellik ile eğitim...\n",
            "Ortalama R²: 0.6115\n",
            "102 özellik ile eğitim...\n",
            "Ortalama R²: 0.6140\n",
            "83 özellik ile eğitim...\n",
            "Ortalama R²: 0.6096\n",
            "\n",
            "RFE Tamamlandı.\n",
            "Son R²: 0.6096\n",
            "Özellik sayısı: 64\n",
            "Test R²: 0.5785\n",
            "\n",
            "Özellik önemleri 'rfe_final_feature_importance.csv' dosyasına kaydedildi.\n",
            "RFE sonrası processed_df sütunları: ['room', 'bathRoom', 'isMapHidden', 'age', 'housingComplex', 'isVideoTypeVimeo', 'stale', 'attr_Kablo TV-Uydu', \"attr_E-5'e yakın\", 'attr_Duşakabin', 'attr_Hidrofor', 'attr_Açık Yüzme Havuzu', 'attr_Kartonpiyer', 'attr_Deniz Ulaşımına yakın', 'attr_Giyinme Odası', 'attr_Vestiyer', 'attr_Su deposu', 'attr_Siding', 'Subcat_daire', 'Subcat_mustakil-ev', 'Subcat_villa', 'net', 'gross', 'subCategory_Bina', 'subCategory_Daire', 'subCategory_Villa', 'roomAndLivingRoom__\"4\"_', 'roomAndLivingRoom__\"4+1\"_', 'roomAndLivingRoom__\"7+1\"_', 'roomAndLivingRoom__\"9 ve üzeri\"_', 'registerState_Kat Mülkiyeti', 'registerState_NaN', 'areas_name_Dibektaş', 'areas_name_Diğer', 'areas_name_Diğer, Soğuksu', 'areas_name_Sapanca Merkez', 'areas_name_SapancaMerkez', 'areas_name_Serdivan Merkez', 'district_name_Arabacıalanı', 'district_name_Bıçkıatik', 'district_name_Camicedit', 'district_name_Kirazlı', 'district_name_Kurtköy Dibektaş', 'district_name_Kuruçeşme', 'district_name_Kırkpınar Soğuksu', 'district_name_Manavpınarı', 'district_name_Ozanlar', 'district_name_Rüstempasa', 'district_name_Yörükler', 'district_name_Şükriye', 'county_name_Hendek', 'county_name_Kocaali', 'county_name_Sapanca', 'county_name_Serdivan', 'residence_name_Müstakil Ev', 'residence_name_MüstakilEv', 'residence_name_İkiz Ev', 'heating_name_Klima', 'heating_name_Merkezi', 'heating_name_Soba', 'buildState_name_İkinci El', 'usage_name_NaN', 'barter_name_NaN', 'furnished_True', 'price', 'listingId']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ÖZELLİK MÜHENDİSLİĞİ"
      ],
      "metadata": {
        "id": "pm0jTLonZE7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Özellik Mühendisliği Fonksiyonu\n",
        "def create_engineered_features(df, numeric_cols=None, log_threshold=1e-6):\n",
        "    df = df.copy()\n",
        "\n",
        "    # Sayısal sütunları seç\n",
        "    if numeric_cols is None:\n",
        "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "    # numeric_cols'un df'de mevcut olduğunu kontrol et\n",
        "    numeric_cols = [col for col in numeric_cols if col in df.columns]\n",
        "    if not numeric_cols:\n",
        "        raise ValueError(\"Hiçbir sayısal sütun bulunamadı veya belirtilen sütunlar veri setinde mevcut değil.\")\n",
        "\n",
        "    print(f\"İşlenecek sayısal sütunlar ({len(numeric_cols)} adet): {numeric_cols}\")\n",
        "\n",
        "    new_features = {}\n",
        "\n",
        "    # 2'li kombinasyonlar: çarpım, oran, toplam, fark\n",
        "    for col1, col2 in combinations(numeric_cols, 2):\n",
        "        new_features[f\"{col1}_x_{col2}\"] = df[col1] * df[col2]\n",
        "        new_features[f\"{col1}_div_{col2}\"] = df[col1] / (df[col2] + log_threshold)\n",
        "        new_features[f\"{col1}_plus_{col2}\"] = df[col1] + df[col2]\n",
        "        new_features[f\"{col1}_minus_{col2}\"] = df[col1] - df[col2]\n",
        "\n",
        "    # 3'lü kombinasyonlar: çarpım\n",
        "    for col1, col2, col3 in combinations(numeric_cols, 3):\n",
        "        new_features[f\"{col1}_x_{col2}_x_{col3}\"] = df[col1] * df[col2] * df[col3]\n",
        "\n",
        "    # Tekil dönüşümler\n",
        "    for col in numeric_cols:\n",
        "        # Negatif veya sıfır değerler için kontrol\n",
        "        new_features[f\"log_{col}\"] = np.log1p(df[col].clip(lower=0))\n",
        "        new_features[f\"sqrt_{col}\"] = np.sqrt(df[col].clip(lower=0))\n",
        "        mean = df[col].mean()\n",
        "        std = df[col].std()\n",
        "        new_features[f\"zscore_{col}\"] = (df[col] - mean) / (std + log_threshold)\n",
        "\n",
        "    # Yeni özellikleri DataFrame'e dönüştür\n",
        "    new_features_df = pd.DataFrame(new_features, index=df.index)\n",
        "\n",
        "    # Ana DataFrame ile birleştir\n",
        "    df = pd.concat([df, new_features_df], axis=1)\n",
        "\n",
        "    print(f\"Toplam yeni özellik sayısı: {len(new_features)}\")\n",
        "    return df\n",
        "\n",
        "# 3. Özellik mühendisliği\n",
        "processed_df = create_engineered_features(processed_df, numeric_cols=numeric_columns)\n",
        "\n",
        "# Son durumu kontrol et\n",
        "print(f\"Son processed_df sütunları: {list(processed_df.columns)}\")\n",
        "print(f\"Son processed_df şekli: {processed_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiHd3HBk37rn",
        "outputId": "9ff1dba4-7326-452f-e8c6-852a82cef619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "İşlenecek sayısal sütunlar (5 adet): ['net', 'gross', 'room', 'bathRoom', 'housingComplex']\n",
            "Toplam yeni özellik sayısı: 65\n",
            "Son processed_df sütunları: ['room', 'bathRoom', 'isMapHidden', 'age', 'housingComplex', 'isVideoTypeVimeo', 'stale', 'attr_Kablo TV-Uydu', \"attr_E-5'e yakın\", 'attr_Duşakabin', 'attr_Hidrofor', 'attr_Açık Yüzme Havuzu', 'attr_Kartonpiyer', 'attr_Deniz Ulaşımına yakın', 'attr_Giyinme Odası', 'attr_Vestiyer', 'attr_Su deposu', 'attr_Siding', 'Subcat_daire', 'Subcat_mustakil-ev', 'Subcat_villa', 'net', 'gross', 'subCategory_Bina', 'subCategory_Daire', 'subCategory_Villa', 'roomAndLivingRoom__\"4\"_', 'roomAndLivingRoom__\"4+1\"_', 'roomAndLivingRoom__\"7+1\"_', 'roomAndLivingRoom__\"9 ve üzeri\"_', 'registerState_Kat Mülkiyeti', 'registerState_NaN', 'areas_name_Dibektaş', 'areas_name_Diğer', 'areas_name_Diğer, Soğuksu', 'areas_name_Sapanca Merkez', 'areas_name_SapancaMerkez', 'areas_name_Serdivan Merkez', 'district_name_Arabacıalanı', 'district_name_Bıçkıatik', 'district_name_Camicedit', 'district_name_Kirazlı', 'district_name_Kurtköy Dibektaş', 'district_name_Kuruçeşme', 'district_name_Kırkpınar Soğuksu', 'district_name_Manavpınarı', 'district_name_Ozanlar', 'district_name_Rüstempasa', 'district_name_Yörükler', 'district_name_Şükriye', 'county_name_Hendek', 'county_name_Kocaali', 'county_name_Sapanca', 'county_name_Serdivan', 'residence_name_Müstakil Ev', 'residence_name_MüstakilEv', 'residence_name_İkiz Ev', 'heating_name_Klima', 'heating_name_Merkezi', 'heating_name_Soba', 'buildState_name_İkinci El', 'usage_name_NaN', 'barter_name_NaN', 'furnished_True', 'price', 'listingId', 'net_x_gross', 'net_div_gross', 'net_plus_gross', 'net_minus_gross', 'net_x_room', 'net_div_room', 'net_plus_room', 'net_minus_room', 'net_x_bathRoom', 'net_div_bathRoom', 'net_plus_bathRoom', 'net_minus_bathRoom', 'net_x_housingComplex', 'net_div_housingComplex', 'net_plus_housingComplex', 'net_minus_housingComplex', 'gross_x_room', 'gross_div_room', 'gross_plus_room', 'gross_minus_room', 'gross_x_bathRoom', 'gross_div_bathRoom', 'gross_plus_bathRoom', 'gross_minus_bathRoom', 'gross_x_housingComplex', 'gross_div_housingComplex', 'gross_plus_housingComplex', 'gross_minus_housingComplex', 'room_x_bathRoom', 'room_div_bathRoom', 'room_plus_bathRoom', 'room_minus_bathRoom', 'room_x_housingComplex', 'room_div_housingComplex', 'room_plus_housingComplex', 'room_minus_housingComplex', 'bathRoom_x_housingComplex', 'bathRoom_div_housingComplex', 'bathRoom_plus_housingComplex', 'bathRoom_minus_housingComplex', 'net_x_gross_x_room', 'net_x_gross_x_bathRoom', 'net_x_gross_x_housingComplex', 'net_x_room_x_bathRoom', 'net_x_room_x_housingComplex', 'net_x_bathRoom_x_housingComplex', 'gross_x_room_x_bathRoom', 'gross_x_room_x_housingComplex', 'gross_x_bathRoom_x_housingComplex', 'room_x_bathRoom_x_housingComplex', 'log_net', 'sqrt_net', 'zscore_net', 'log_gross', 'sqrt_gross', 'zscore_gross', 'log_room', 'sqrt_room', 'zscore_room', 'log_bathRoom', 'sqrt_bathRoom', 'zscore_bathRoom', 'log_housingComplex', 'sqrt_housingComplex', 'zscore_housingComplex']\n",
            "Son processed_df şekli: (2140, 131)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SEÇİLEN VE EN İYİ ÖZELLİKLERİN TÜRETİLDİĞİ VERİ SETİNDE DEFAULT PARAMETRELERLE EĞİTİM"
      ],
      "metadata": {
        "id": "YGncalryZI_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_xgboost = run_xgboost_model(optuna_enabled=False)"
      ],
      "metadata": {
        "id": "T-iXboHV3-AL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e4f66a-8a67-46a3-c686-f5bccd82bdc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sınıf frekansları:\n",
            " housingComplex\n",
            "0    1748\n",
            "1     392\n",
            "Name: count, dtype: int64\n",
            "scale_pos_weight: 4.4545\n",
            "Fold 1:\n",
            "  Doğruluk: 1.0000\n",
            "  F1 Skoru: 1.0000\n",
            "  MCC: 1.0000\n",
            "  AUC-ROC: 1.0000\n",
            "--------------------------------------------------\n",
            "Fold 2:\n",
            "  Doğruluk: 1.0000\n",
            "  F1 Skoru: 1.0000\n",
            "  MCC: 1.0000\n",
            "  AUC-ROC: 1.0000\n",
            "--------------------------------------------------\n",
            "Fold 3:\n",
            "  Doğruluk: 1.0000\n",
            "  F1 Skoru: 1.0000\n",
            "  MCC: 1.0000\n",
            "  AUC-ROC: 1.0000\n",
            "--------------------------------------------------\n",
            "Fold 4:\n",
            "  Doğruluk: 0.9975\n",
            "  F1 Skoru: 0.9939\n",
            "  MCC: 0.9924\n",
            "  AUC-ROC: 0.9985\n",
            "--------------------------------------------------\n",
            "Fold 5:\n",
            "  Doğruluk: 1.0000\n",
            "  F1 Skoru: 1.0000\n",
            "  MCC: 1.0000\n",
            "  AUC-ROC: 1.0000\n",
            "--------------------------------------------------\n",
            "5 Katlı Çapraz Doğrulama Ortalama Sonuçları:\n",
            "Ortalama Doğruluk: 0.9995 ± 0.0010\n",
            "Ortalama F1 Skoru: 0.9988 ± 0.0025\n",
            "Ortalama MCC: 0.9985 ± 0.0031\n",
            "Ortalama AUC-ROC: 0.9997 ± 0.0006\n",
            "\n",
            "Ayrılan Test Seti Üzerinde Nihai Sonuçlar:\n",
            "Doğruluk: 1.0000\n",
            "F1 Skoru: 1.0000\n",
            "MCC: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Sınıflandırma Raporu (Test Seti):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        82\n",
            "           1       1.00      1.00      1.00        18\n",
            "\n",
            "    accuracy                           1.00       100\n",
            "   macro avg       1.00      1.00      1.00       100\n",
            "weighted avg       1.00      1.00      1.00       100\n",
            "\n",
            "\n",
            "Tahminler ve gerçek değerler 'test_predictions.xlsx' dosyasına kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SEÇİLEN VE EN İYİ ÖZELLİKLERİN TÜRETİLDİĞİ VERİ SETİNDE HİPER PARAMETRE OPTİMİZASYONU VE EĞİTİM"
      ],
      "metadata": {
        "id": "dfjMkeofZSi7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_xgboost = run_xgboost_model(optuna_enabled=True)"
      ],
      "metadata": {
        "id": "5qGGJfKe4AbJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2a52139-df56-49d4-be41-64492cc80436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 07:19:21,387] A new study created in memory with name: no-name-3c513260-c345-471e-a533-6fff3c636698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sınıf frekansları:\n",
            " housingComplex\n",
            "0    1748\n",
            "1     392\n",
            "Name: count, dtype: int64\n",
            "scale_pos_weight: 4.4545\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 07:19:22,643] Trial 0 finished with value: 0.9987730061349694 and parameters: {'eta': 0.23063122454934556, 'max_depth': 3, 'n_estimators': 893, 'subsample': 0.9886790061791765, 'colsample_bytree': 0.5049188672306206, 'min_child_weight': 6, 'gamma': 3.5278907460658875, 'reg_alpha': 3.877080894744467, 'reg_lambda': 8.010280716619377}. Best is trial 0 with value: 0.9987730061349694.\n",
            "[I 2025-05-07 07:19:23,900] Trial 1 finished with value: 0.9987730061349694 and parameters: {'eta': 0.2245156009258067, 'max_depth': 9, 'n_estimators': 539, 'subsample': 0.8567608665606143, 'colsample_bytree': 0.6546532645093701, 'min_child_weight': 10, 'gamma': 0.20726770525873295, 'reg_alpha': 3.9898542082771793, 'reg_lambda': 0.06912201141258567}. Best is trial 0 with value: 0.9987730061349694.\n",
            "[I 2025-05-07 07:19:25,435] Trial 2 finished with value: 0.9987577639751553 and parameters: {'eta': 0.14751750275683365, 'max_depth': 10, 'n_estimators': 635, 'subsample': 0.6129898246186738, 'colsample_bytree': 0.5946298280498659, 'min_child_weight': 9, 'gamma': 4.3821962534157075, 'reg_alpha': 0.8997743775807965, 'reg_lambda': 7.9660040893313475}. Best is trial 0 with value: 0.9987730061349694.\n",
            "[I 2025-05-07 07:19:26,725] Trial 3 finished with value: 0.9974999999999999 and parameters: {'eta': 0.049975309240978615, 'max_depth': 5, 'n_estimators': 434, 'subsample': 0.5233851591180214, 'colsample_bytree': 0.7592511103504817, 'min_child_weight': 10, 'gamma': 3.8963337459059364, 'reg_alpha': 1.6069594298198853, 'reg_lambda': 9.718101884251398}. Best is trial 0 with value: 0.9987730061349694.\n",
            "[I 2025-05-07 07:19:28,045] Trial 4 finished with value: 0.9987577639751553 and parameters: {'eta': 0.21280491244074706, 'max_depth': 10, 'n_estimators': 135, 'subsample': 0.9264872682002114, 'colsample_bytree': 0.999687593195681, 'min_child_weight': 10, 'gamma': 2.613500932998874, 'reg_alpha': 0.9102795808831377, 'reg_lambda': 3.073305560251657}. Best is trial 0 with value: 0.9987730061349694.\n",
            "[I 2025-05-07 07:19:29,334] Trial 5 finished with value: 0.9987730061349694 and parameters: {'eta': 0.03388480998045989, 'max_depth': 8, 'n_estimators': 892, 'subsample': 0.77751221163417, 'colsample_bytree': 0.5966920621447114, 'min_child_weight': 7, 'gamma': 4.000884174037847, 'reg_alpha': 9.127316475742907, 'reg_lambda': 0.22200935932454868}. Best is trial 0 with value: 0.9987730061349694.\n",
            "[I 2025-05-07 07:19:31,388] Trial 6 finished with value: 0.9974999999999999 and parameters: {'eta': 0.015217766990394344, 'max_depth': 6, 'n_estimators': 570, 'subsample': 0.5482517595277002, 'colsample_bytree': 0.8758522799224391, 'min_child_weight': 7, 'gamma': 1.0930750621085932, 'reg_alpha': 0.9901546234107261, 'reg_lambda': 5.087338943786717}. Best is trial 0 with value: 0.9987730061349694.\n",
            "[I 2025-05-07 07:19:33,582] Trial 7 finished with value: 0.9974999999999999 and parameters: {'eta': 0.10358797859714047, 'max_depth': 10, 'n_estimators': 443, 'subsample': 0.7271102631126025, 'colsample_bytree': 0.6973055864452211, 'min_child_weight': 4, 'gamma': 1.2157727100241962, 'reg_alpha': 4.254794818338894, 'reg_lambda': 2.727871405768484}. Best is trial 0 with value: 0.9987730061349694.\n",
            "[I 2025-05-07 07:19:34,825] Trial 8 finished with value: 0.9987577639751553 and parameters: {'eta': 0.11740593581705709, 'max_depth': 3, 'n_estimators': 321, 'subsample': 0.7527113434237573, 'colsample_bytree': 0.5908028515950914, 'min_child_weight': 5, 'gamma': 4.512580103215077, 'reg_alpha': 1.5593936345560144, 'reg_lambda': 5.757540474822489}. Best is trial 0 with value: 0.9987730061349694.\n",
            "[I 2025-05-07 07:19:36,249] Trial 9 finished with value: 0.9987730061349694 and parameters: {'eta': 0.11455047604643692, 'max_depth': 6, 'n_estimators': 571, 'subsample': 0.9141360592275513, 'colsample_bytree': 0.5237301165540705, 'min_child_weight': 8, 'gamma': 1.5226309401701061, 'reg_alpha': 6.30075027950088, 'reg_lambda': 6.450571190952776}. Best is trial 0 with value: 0.9987730061349694.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En iyi parametreler: {'eta': 0.23063122454934556, 'max_depth': 3, 'n_estimators': 893, 'subsample': 0.9886790061791765, 'colsample_bytree': 0.5049188672306206, 'min_child_weight': 6, 'gamma': 3.5278907460658875, 'reg_alpha': 3.877080894744467, 'reg_lambda': 8.010280716619377, 'objective': 'binary:logistic', 'random_state': 42, 'eval_metric': 'auc', 'early_stopping_rounds': 30, 'scale_pos_weight': 4.454545454545454}\n",
            "Fold 1:\n",
            "  Doğruluk: 1.0000\n",
            "  F1 Skoru: 1.0000\n",
            "  MCC: 1.0000\n",
            "  AUC-ROC: 1.0000\n",
            "--------------------------------------------------\n",
            "Fold 2:\n",
            "  Doğruluk: 1.0000\n",
            "  F1 Skoru: 1.0000\n",
            "  MCC: 1.0000\n",
            "  AUC-ROC: 1.0000\n",
            "--------------------------------------------------\n",
            "Fold 3:\n",
            "  Doğruluk: 1.0000\n",
            "  F1 Skoru: 1.0000\n",
            "  MCC: 1.0000\n",
            "  AUC-ROC: 1.0000\n",
            "--------------------------------------------------\n",
            "Fold 4:\n",
            "  Doğruluk: 0.9975\n",
            "  F1 Skoru: 0.9939\n",
            "  MCC: 0.9924\n",
            "  AUC-ROC: 0.9985\n",
            "--------------------------------------------------\n",
            "Fold 5:\n",
            "  Doğruluk: 1.0000\n",
            "  F1 Skoru: 1.0000\n",
            "  MCC: 1.0000\n",
            "  AUC-ROC: 1.0000\n",
            "--------------------------------------------------\n",
            "5 Katlı Çapraz Doğrulama Ortalama Sonuçları:\n",
            "Ortalama Doğruluk: 0.9995 ± 0.0010\n",
            "Ortalama F1 Skoru: 0.9988 ± 0.0025\n",
            "Ortalama MCC: 0.9985 ± 0.0031\n",
            "Ortalama AUC-ROC: 0.9997 ± 0.0006\n",
            "\n",
            "Ayrılan Test Seti Üzerinde Nihai Sonuçlar:\n",
            "Doğruluk: 1.0000\n",
            "F1 Skoru: 1.0000\n",
            "MCC: 1.0000\n",
            "AUC-ROC: 1.0000\n",
            "\n",
            "Sınıflandırma Raporu (Test Seti):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        82\n",
            "           1       1.00      1.00      1.00        18\n",
            "\n",
            "    accuracy                           1.00       100\n",
            "   macro avg       1.00      1.00      1.00       100\n",
            "weighted avg       1.00      1.00      1.00       100\n",
            "\n",
            "\n",
            "Tahminler ve gerçek değerler 'test_predictions.xlsx' dosyasına kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "X = processed_df.drop(columns=['housingComplex', 'listingId'])\n",
        "y = processed_df['housingComplex']\n",
        "\n",
        "mi = mutual_info_classif(X, y)\n",
        "info_df = pd.DataFrame({'feature': X.columns, 'mutual_info': mi})\n",
        "info_df.sort_values(by='mutual_info', ascending=False).head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "ooWSKVeHkqN6",
        "outputId": "3563d46f-182d-45ad-81f0-28e598c5c644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           feature  mutual_info\n",
              "127            sqrt_housingComplex     0.476645\n",
              "76            net_x_housingComplex     0.476411\n",
              "88          gross_x_housingComplex     0.476411\n",
              "106   net_x_gross_x_housingComplex     0.476411\n",
              "108    net_x_room_x_housingComplex     0.476411\n",
              "96           room_x_housingComplex     0.476411\n",
              "89        gross_div_housingComplex     0.476411\n",
              "126             log_housingComplex     0.476411\n",
              "111  gross_x_room_x_housingComplex     0.476411\n",
              "128          zscore_housingComplex     0.476411"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-156ead04-0c8e-4b28-8a81-f5afc1440c5c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>mutual_info</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>sqrt_housingComplex</td>\n",
              "      <td>0.476645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>net_x_housingComplex</td>\n",
              "      <td>0.476411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>gross_x_housingComplex</td>\n",
              "      <td>0.476411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>net_x_gross_x_housingComplex</td>\n",
              "      <td>0.476411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>net_x_room_x_housingComplex</td>\n",
              "      <td>0.476411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>room_x_housingComplex</td>\n",
              "      <td>0.476411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>gross_div_housingComplex</td>\n",
              "      <td>0.476411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>log_housingComplex</td>\n",
              "      <td>0.476411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>gross_x_room_x_housingComplex</td>\n",
              "      <td>0.476411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>zscore_housingComplex</td>\n",
              "      <td>0.476411</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-156ead04-0c8e-4b28-8a81-f5afc1440c5c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-156ead04-0c8e-4b28-8a81-f5afc1440c5c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-156ead04-0c8e-4b28-8a81-f5afc1440c5c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-028154ef-0b14-4c41-8cd3-b8bb2cc9316a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-028154ef-0b14-4c41-8cd3-b8bb2cc9316a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-028154ef-0b14-4c41-8cd3-b8bb2cc9316a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"info_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"feature\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"gross_x_room_x_housingComplex\",\n          \"net_x_housingComplex\",\n          \"room_x_housingComplex\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mutual_info\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.388499205999219e-05,\n        \"min\": 0.47641148738743777,\n        \"max\": 0.4766451322472508,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.47641148738743777,\n          0.4766451322472508\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_remove = [\n",
        "    'zscore_housingComplex',\n",
        "    'net_x_housingComplex',\n",
        "    'gross_x_housingComplex',\n",
        "    'net_x_gross_x_housingComplex',\n",
        "    'net_x_room_x_housingComplex',\n",
        "    'room_x_housingComplex',\n",
        "    'gross_div_housingComplex',\n",
        "    'log_housingComplex',\n",
        "    'gross_x_room_x_housingComplex',\n",
        "    'sqrt_housingComplex'\n",
        "]\n",
        "\n",
        "filtered_df = processed_df.drop(columns=columns_to_remove, errors='ignore')"
      ],
      "metadata": {
        "id": "vX6FqBjhksoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef, roc_auc_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import optuna\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def run_knn_model_realistic(\n",
        "    df,\n",
        "    target_column='housingComplex',\n",
        "    test_ratio=0.2,\n",
        "    random_state=42,\n",
        "    n_splits=5,\n",
        "    optuna_enabled=False,\n",
        "    n_trials=20\n",
        "):\n",
        "    feature_columns = [col for col in df.columns if col not in [target_column, 'listingId']]\n",
        "\n",
        "    # 1. Gerçek test setini ayır\n",
        "    train_df, test_df = train_test_split(\n",
        "        df, test_size=test_ratio, random_state=random_state, stratify=df[target_column]\n",
        "    )\n",
        "\n",
        "    X_train_full = train_df[feature_columns]\n",
        "    y_train_full = train_df[target_column]\n",
        "    X_test = test_df[feature_columns]\n",
        "    y_test = test_df[target_column]\n",
        "\n",
        "    # 2. Optuna ile en iyi parametreyi bul\n",
        "    def objective(trial):\n",
        "        n_neighbors = trial.suggest_int('n_neighbors', 3, 25)\n",
        "        metric = trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'minkowski'])\n",
        "        f1s = []\n",
        "\n",
        "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "        for train_idx, val_idx in kf.split(X_train_full):\n",
        "            X_train, X_val = X_train_full.iloc[train_idx], X_train_full.iloc[val_idx]\n",
        "            y_train, y_val = y_train_full.iloc[train_idx], y_train_full.iloc[val_idx]\n",
        "\n",
        "            scaler = StandardScaler()\n",
        "            X_train_scaled = scaler.fit_transform(X_train)\n",
        "            X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "            model = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric)\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "            y_pred = model.predict(X_val_scaled)\n",
        "            f1s.append(f1_score(y_val, y_pred))\n",
        "\n",
        "        return np.mean(f1s)\n",
        "\n",
        "    if optuna_enabled:\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(objective, n_trials=n_trials)\n",
        "        best_params = study.best_params\n",
        "        print(\"Best Optuna Parameters:\", best_params)\n",
        "    else:\n",
        "        best_params = {'n_neighbors': 5, 'metric': 'minkowski'}\n",
        "\n",
        "    # 3. KFold ile çapraz doğrulama skorları\n",
        "    accs, f1s, mccs, aucs = [], [], [], []\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    for train_idx, val_idx in kf.split(X_train_full):\n",
        "        X_train, X_val = X_train_full.iloc[train_idx], X_train_full.iloc[val_idx]\n",
        "        y_train, y_val = y_train_full.iloc[train_idx], y_train_full.iloc[val_idx]\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "        model = KNeighborsClassifier(**best_params)\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_val_scaled)\n",
        "        y_prob = model.predict_proba(X_val_scaled)[:, 1]\n",
        "\n",
        "        accs.append(accuracy_score(y_val, y_pred))\n",
        "        f1s.append(f1_score(y_val, y_pred))\n",
        "        mccs.append(matthews_corrcoef(y_val, y_pred))\n",
        "        aucs.append(roc_auc_score(y_val, y_prob))\n",
        "\n",
        "    print(\"\\nCross-Validation Results:\")\n",
        "    print(f\"Accuracy: {np.mean(accs):.4f} ± {np.std(accs):.4f}\")\n",
        "    print(f\"F1 Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
        "    print(f\"MCC: {np.mean(mccs):.4f} ± {np.std(mccs):.4f}\")\n",
        "    print(f\"AUC-ROC: {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
        "\n",
        "    # 4. Gerçek test setiyle değerlendirme\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train_full)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    model = KNeighborsClassifier(**best_params)\n",
        "    model.fit(X_train_scaled, y_train_full)\n",
        "    y_pred_test = model.predict(X_test_scaled)\n",
        "    y_prob_test = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "    print(\"\\nTest Set Results:\")\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_test, y_pred_test):.4f}\")\n",
        "    print(f\"MCC: {matthews_corrcoef(y_test, y_pred_test):.4f}\")\n",
        "    print(f\"AUC-ROC: {roc_auc_score(y_test, y_prob_test):.4f}\")\n",
        "    print(classification_report(y_test, y_pred_test))\n",
        "\n",
        "    return {\n",
        "        \"cv_accuracy\": np.mean(accs),\n",
        "        \"cv_f1\": np.mean(f1s),\n",
        "        \"cv_mcc\": np.mean(mccs),\n",
        "        \"cv_auc\": np.mean(aucs),\n",
        "        \"test_accuracy\": accuracy_score(y_test, y_pred_test),\n",
        "        \"test_f1\": f1_score(y_test, y_pred_test),\n",
        "        \"test_mcc\": matthews_corrcoef(y_test, y_pred_test),\n",
        "        \"test_auc\": roc_auc_score(y_test, y_prob_test)\n",
        "    }\n"
      ],
      "metadata": {
        "id": "2O3dstIpk_tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = run_knn_model_realistic(df=filtered_df, optuna_enabled=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlQNO6Z0lByo",
        "outputId": "e75e9753-d219-4bde-cdac-7e3a78e969db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 07:19:39,322] A new study created in memory with name: no-name-4035ff1b-ec42-442a-a252-e6ee46517cd5\n",
            "[I 2025-05-07 07:19:39,555] Trial 0 finished with value: 0.8866432580508468 and parameters: {'n_neighbors': 7, 'metric': 'minkowski'}. Best is trial 0 with value: 0.8866432580508468.\n",
            "[I 2025-05-07 07:19:39,775] Trial 1 finished with value: 0.8766435865019936 and parameters: {'n_neighbors': 11, 'metric': 'minkowski'}. Best is trial 0 with value: 0.8866432580508468.\n",
            "[I 2025-05-07 07:19:40,022] Trial 2 finished with value: 0.8590623790525601 and parameters: {'n_neighbors': 8, 'metric': 'euclidean'}. Best is trial 0 with value: 0.8866432580508468.\n",
            "[I 2025-05-07 07:19:40,247] Trial 3 finished with value: 0.8646396162500309 and parameters: {'n_neighbors': 23, 'metric': 'euclidean'}. Best is trial 0 with value: 0.8866432580508468.\n",
            "[I 2025-05-07 07:19:40,468] Trial 4 finished with value: 0.8798789868630023 and parameters: {'n_neighbors': 3, 'metric': 'minkowski'}. Best is trial 0 with value: 0.8866432580508468.\n",
            "[I 2025-05-07 07:19:40,705] Trial 5 finished with value: 0.8571275017522483 and parameters: {'n_neighbors': 22, 'metric': 'euclidean'}. Best is trial 0 with value: 0.8866432580508468.\n",
            "[I 2025-05-07 07:19:41,276] Trial 6 finished with value: 0.9659913748337698 and parameters: {'n_neighbors': 18, 'metric': 'manhattan'}. Best is trial 6 with value: 0.9659913748337698.\n",
            "[I 2025-05-07 07:19:41,867] Trial 7 finished with value: 0.9465108096659629 and parameters: {'n_neighbors': 24, 'metric': 'manhattan'}. Best is trial 6 with value: 0.9659913748337698.\n",
            "[I 2025-05-07 07:19:42,090] Trial 8 finished with value: 0.8975413259130205 and parameters: {'n_neighbors': 9, 'metric': 'euclidean'}. Best is trial 6 with value: 0.9659913748337698.\n",
            "[I 2025-05-07 07:19:42,297] Trial 9 finished with value: 0.8798789868630023 and parameters: {'n_neighbors': 3, 'metric': 'euclidean'}. Best is trial 6 with value: 0.9659913748337698.\n",
            "[I 2025-05-07 07:19:42,877] Trial 10 finished with value: 0.9659913748337698 and parameters: {'n_neighbors': 18, 'metric': 'manhattan'}. Best is trial 6 with value: 0.9659913748337698.\n",
            "[I 2025-05-07 07:19:43,664] Trial 11 finished with value: 0.9707602424297919 and parameters: {'n_neighbors': 17, 'metric': 'manhattan'}. Best is trial 11 with value: 0.9707602424297919.\n",
            "[I 2025-05-07 07:19:44,411] Trial 12 finished with value: 0.9605197637162041 and parameters: {'n_neighbors': 16, 'metric': 'manhattan'}. Best is trial 11 with value: 0.9707602424297919.\n",
            "[I 2025-05-07 07:19:45,222] Trial 13 finished with value: 0.9725604105330167 and parameters: {'n_neighbors': 19, 'metric': 'manhattan'}. Best is trial 13 with value: 0.9725604105330167.\n",
            "[I 2025-05-07 07:19:45,805] Trial 14 finished with value: 0.9662899942166977 and parameters: {'n_neighbors': 14, 'metric': 'manhattan'}. Best is trial 13 with value: 0.9725604105330167.\n",
            "[I 2025-05-07 07:19:46,387] Trial 15 finished with value: 0.9640218012981171 and parameters: {'n_neighbors': 20, 'metric': 'manhattan'}. Best is trial 13 with value: 0.9725604105330167.\n",
            "[I 2025-05-07 07:19:46,945] Trial 16 finished with value: 0.9662899942166977 and parameters: {'n_neighbors': 14, 'metric': 'manhattan'}. Best is trial 13 with value: 0.9725604105330167.\n",
            "[I 2025-05-07 07:19:47,517] Trial 17 finished with value: 0.9659913748337698 and parameters: {'n_neighbors': 18, 'metric': 'manhattan'}. Best is trial 13 with value: 0.9725604105330167.\n",
            "[I 2025-05-07 07:19:48,089] Trial 18 finished with value: 0.9704146648985248 and parameters: {'n_neighbors': 21, 'metric': 'manhattan'}. Best is trial 13 with value: 0.9725604105330167.\n",
            "[I 2025-05-07 07:19:48,646] Trial 19 finished with value: 0.9686796663711364 and parameters: {'n_neighbors': 12, 'metric': 'manhattan'}. Best is trial 13 with value: 0.9725604105330167.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Optuna Parameters: {'n_neighbors': 19, 'metric': 'manhattan'}\n",
            "\n",
            "Cross-Validation Results:\n",
            "Accuracy: 0.9901 ± 0.0057\n",
            "F1 Score: 0.9726 ± 0.0152\n",
            "MCC: 0.9672 ± 0.0182\n",
            "AUC-ROC: 0.9999 ± 0.0001\n",
            "\n",
            "Test Set Results:\n",
            "Accuracy: 0.9836\n",
            "F1 Score: 0.9530\n",
            "MCC: 0.9447\n",
            "AUC-ROC: 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       350\n",
            "           1       1.00      0.91      0.95        78\n",
            "\n",
            "    accuracy                           0.98       428\n",
            "   macro avg       0.99      0.96      0.97       428\n",
            "weighted avg       0.98      0.98      0.98       428\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in result.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dhWvp1MlFr_",
        "outputId": "19f5421a-f844-4aa5-bcd1-25edfa8be48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv_accuracy: 0.9901\n",
            "cv_f1: 0.9726\n",
            "cv_mcc: 0.9672\n",
            "cv_auc: 0.9999\n",
            "test_accuracy: 0.9836\n",
            "test_f1: 0.9530\n",
            "test_mcc: 0.9447\n",
            "test_auc: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correlations = processed_df.corr(numeric_only=True)['housingComplex'].abs().sort_values(ascending=False)\n",
        "print(correlations.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG9x6zFXlJZ2",
        "outputId": "f88479bb-18ad-4250-9df2-d3b2b9c099df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "log_housingComplex                   1.000000\n",
            "zscore_housingComplex                1.000000\n",
            "housingComplex                       1.000000\n",
            "sqrt_housingComplex                  1.000000\n",
            "room_x_housingComplex                0.969278\n",
            "net_x_housingComplex                 0.879892\n",
            "room_div_housingComplex              0.869001\n",
            "gross_x_housingComplex               0.866248\n",
            "net_x_room_x_housingComplex          0.778019\n",
            "gross_x_room_x_housingComplex        0.761745\n",
            "bathRoom_x_housingComplex            0.760259\n",
            "room_x_bathRoom_x_housingComplex     0.676513\n",
            "net_x_gross_x_housingComplex         0.599038\n",
            "net_x_bathRoom_x_housingComplex      0.545484\n",
            "gross_x_bathRoom_x_housingComplex    0.534276\n",
            "bathRoom_div_housingComplex          0.484652\n",
            "net_div_housingComplex               0.400737\n",
            "room_minus_housingComplex            0.368422\n",
            "bathRoom_minus_housingComplex        0.321867\n",
            "attr_Açık Yüzme Havuzu               0.302733\n",
            "Name: housingComplex, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "high_corr_cols = correlations[correlations > 0.40].index.tolist()\n",
        "high_corr_cols.remove('housingComplex')  # hedef değişkeni sil\n",
        "\n",
        "filtered_df_v2 = processed_df.drop(columns=high_corr_cols, errors='ignore')"
      ],
      "metadata": {
        "id": "4WKfPjzIlKTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = run_knn_model_realistic(df=filtered_df_v2, optuna_enabled=True)"
      ],
      "metadata": {
        "id": "cPv-w-iClN_k",
        "outputId": "3dd22a3b-a67a-4b60-85be-a281691361d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-05-07 07:19:50,059] A new study created in memory with name: no-name-8979441d-9769-4d6a-bfc9-5680d8be8b39\n",
            "[I 2025-05-07 07:19:50,292] Trial 0 finished with value: 0.45837290297724265 and parameters: {'n_neighbors': 9, 'metric': 'minkowski'}. Best is trial 0 with value: 0.45837290297724265.\n",
            "[I 2025-05-07 07:19:50,532] Trial 1 finished with value: 0.3057033028483387 and parameters: {'n_neighbors': 18, 'metric': 'euclidean'}. Best is trial 0 with value: 0.45837290297724265.\n",
            "[I 2025-05-07 07:19:50,755] Trial 2 finished with value: 0.4523997784393824 and parameters: {'n_neighbors': 11, 'metric': 'minkowski'}. Best is trial 0 with value: 0.45837290297724265.\n",
            "[I 2025-05-07 07:19:50,976] Trial 3 finished with value: 0.45639437695173657 and parameters: {'n_neighbors': 4, 'metric': 'minkowski'}. Best is trial 0 with value: 0.45837290297724265.\n",
            "[I 2025-05-07 07:19:51,533] Trial 4 finished with value: 0.5284973067432865 and parameters: {'n_neighbors': 18, 'metric': 'manhattan'}. Best is trial 4 with value: 0.5284973067432865.\n",
            "[I 2025-05-07 07:19:51,764] Trial 5 finished with value: 0.25752650857914017 and parameters: {'n_neighbors': 24, 'metric': 'euclidean'}. Best is trial 4 with value: 0.5284973067432865.\n",
            "[I 2025-05-07 07:19:52,261] Trial 6 finished with value: 0.6762684026292999 and parameters: {'n_neighbors': 4, 'metric': 'manhattan'}. Best is trial 6 with value: 0.6762684026292999.\n",
            "[I 2025-05-07 07:19:52,496] Trial 7 finished with value: 0.2852871032838012 and parameters: {'n_neighbors': 22, 'metric': 'minkowski'}. Best is trial 6 with value: 0.6762684026292999.\n",
            "[I 2025-05-07 07:19:52,721] Trial 8 finished with value: 0.4854887172791268 and parameters: {'n_neighbors': 7, 'metric': 'euclidean'}. Best is trial 6 with value: 0.6762684026292999.\n",
            "[I 2025-05-07 07:19:52,942] Trial 9 finished with value: 0.3057033028483387 and parameters: {'n_neighbors': 18, 'metric': 'minkowski'}. Best is trial 6 with value: 0.6762684026292999.\n",
            "[I 2025-05-07 07:19:53,477] Trial 10 finished with value: 0.7763319652606655 and parameters: {'n_neighbors': 3, 'metric': 'manhattan'}. Best is trial 10 with value: 0.7763319652606655.\n",
            "[I 2025-05-07 07:19:54,002] Trial 11 finished with value: 0.7763319652606655 and parameters: {'n_neighbors': 3, 'metric': 'manhattan'}. Best is trial 10 with value: 0.7763319652606655.\n",
            "[I 2025-05-07 07:19:54,559] Trial 12 finished with value: 0.6762684026292999 and parameters: {'n_neighbors': 4, 'metric': 'manhattan'}. Best is trial 10 with value: 0.7763319652606655.\n",
            "[I 2025-05-07 07:19:55,093] Trial 13 finished with value: 0.6666342958668171 and parameters: {'n_neighbors': 13, 'metric': 'manhattan'}. Best is trial 10 with value: 0.7763319652606655.\n",
            "[I 2025-05-07 07:19:55,743] Trial 14 finished with value: 0.7157249757467702 and parameters: {'n_neighbors': 7, 'metric': 'manhattan'}. Best is trial 10 with value: 0.7763319652606655.\n",
            "[I 2025-05-07 07:19:56,456] Trial 15 finished with value: 0.7763319652606655 and parameters: {'n_neighbors': 3, 'metric': 'manhattan'}. Best is trial 10 with value: 0.7763319652606655.\n",
            "[I 2025-05-07 07:19:57,190] Trial 16 finished with value: 0.7157249757467702 and parameters: {'n_neighbors': 7, 'metric': 'manhattan'}. Best is trial 10 with value: 0.7763319652606655.\n",
            "[I 2025-05-07 07:19:57,941] Trial 17 finished with value: 0.6060323886639677 and parameters: {'n_neighbors': 14, 'metric': 'manhattan'}. Best is trial 10 with value: 0.7763319652606655.\n",
            "[I 2025-05-07 07:19:58,466] Trial 18 finished with value: 0.6592910070828897 and parameters: {'n_neighbors': 10, 'metric': 'manhattan'}. Best is trial 10 with value: 0.7763319652606655.\n",
            "[I 2025-05-07 07:19:58,998] Trial 19 finished with value: 0.6528158219815143 and parameters: {'n_neighbors': 6, 'metric': 'manhattan'}. Best is trial 10 with value: 0.7763319652606655.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Optuna Parameters: {'n_neighbors': 3, 'metric': 'manhattan'}\n",
            "\n",
            "Cross-Validation Results:\n",
            "Accuracy: 0.9258 ± 0.0072\n",
            "F1 Score: 0.7763 ± 0.0200\n",
            "MCC: 0.7394 ± 0.0228\n",
            "AUC-ROC: 0.9389 ± 0.0124\n",
            "\n",
            "Test Set Results:\n",
            "Accuracy: 0.9159\n",
            "F1 Score: 0.7465\n",
            "MCC: 0.7015\n",
            "AUC-ROC: 0.9305\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95       350\n",
            "           1       0.83      0.68      0.75        78\n",
            "\n",
            "    accuracy                           0.92       428\n",
            "   macro avg       0.88      0.82      0.85       428\n",
            "weighted avg       0.91      0.92      0.91       428\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in result.items():\n",
        "    print(f\"{k}: {v:.4f}\")"
      ],
      "metadata": {
        "id": "BQ8iYOu4lR5s",
        "outputId": "f72c6199-15e5-4306-d21d-c94ba64457df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cv_accuracy: 0.9258\n",
            "cv_f1: 0.7763\n",
            "cv_mcc: 0.7394\n",
            "cv_auc: 0.9389\n",
            "test_accuracy: 0.9159\n",
            "test_f1: 0.7465\n",
            "test_mcc: 0.7015\n",
            "test_auc: 0.9305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "T3kvBPaiGaTJ"
      }
    }
  ]
}